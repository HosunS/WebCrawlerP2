¦Ifinal_url¡DtypeLhttp_headers¢DtypeEvalue†¢Ak¢DtypeEvalueNContent-LengthAv¢DtypeEvalueD1269¢Ak¢DtypeEvalueMAccept-RangesAv¢DtypeEvalueEbytes¢Ak¢DtypeEvalueFServerAv¢DtypeEvalueX4Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips SVN/1.7.14¢Ak¢DtypeEvalueMLast-ModifiedAv¢DtypeEvalueXMon, 26 Nov 2018 23:18:00 GMT¢Ak¢DtypeEvalueDETagAv¢DtypeEvalueS"4f5-57b998b4b58a2"¢Ak¢DtypeEvalueDDateAv¢DtypeEvalueXSun, 03 Feb 2019 00:56:19 GMTKraw_content¢DtypeEvalueYõ#one way to do least absolute value regression is through a quantile regression package
install.packages("quantreg")
library(quantreg)
library(tidyverse)
datainput <- read_csv("H://HAL/Courses/Stat210//copier.csv")
#datainput <- read_csv("D://Stat210//copier.csv")
copiers <- data.frame(datainput)

# data used to model amount of time required for a service call in terms of the number of copiers
# data includes a couple of outliers 
# compare deletion of outliers with least absolute value regression
#
# time = amount of time required
# copiers = number of copiers serviced

plot(copiers$copiers, copiers$time, type="p")
# regression 
copiers_reg <- lm(time ~ copiers, data=copiers)
summary(copiers_reg)
# check assumptions - residuals vs fitted values
copiers_reg$stdres <- rstandard(copiers_reg)
ggplot() +
  geom_point(data=copiers, mapping=aes(x=copiers_reg$fitted.values, y=copiers_reg$stdres)) 
# check assumptions - normality
qqnorm(copiers_reg$stdres)

# notice a couple of outliers 
# rerun regression without the two outliers
copiers_reg2 <- lm(time[1:45] ~ copiers[1:45], data=copiers)
summary(copiers_reg2)
# try least absolute value regression
median_reg <- rq(time ~ copiers, tau = 0.5, data=copiers)
summary(median_reg)Mis_redirected¢DtypeEvalueôIhttp_code¢DtypeEvalueÈQdownload_complete¢DtypeEvalueõ
¦Ifinal_url¢DtypeEvaluex/https://www.ics.uci.edu/~yamingy/bayesD_demo1.rLhttp_headers¢DtypeEvalue†¢Ak¢DtypeEvalueNContent-LengthAv¢DtypeEvalueC841¢Ak¢DtypeEvalueMAccept-RangesAv¢DtypeEvalueEbytes¢Ak¢DtypeEvalueFServerAv¢DtypeEvalueX4Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips SVN/1.7.14¢Ak¢DtypeEvalueMLast-ModifiedAv¢DtypeEvalueXFri, 12 Mar 2010 18:24:07 GMT¢Ak¢DtypeEvalueDETagAv¢DtypeEvalueS"349-4819ea309ffc0"¢Ak¢DtypeEvalueDDateAv¢DtypeEvalueXSun, 27 Jan 2019 06:01:42 GMTKraw_content¢DtypeEvalueYIsource("bayesD_cocktail.r")

## setting up information matrices for a logistic regression model
n=30
m=2
X=matrix(nrow=n, ncol=m)   
X[,1]=1
X[,2]=3*(1:n)/n-1
      
A=array(dim=c(25, n, m, m));   
for(i in 1:5)
  for(j in 1:5){
    theta=c(i-3, j-3)
    eta=X%*%theta
    for(k in 1:n)   
      A[(i-1)*5+j, k, ,]=exp(eta[k])/(1+exp(eta[k]))^2 * X[k,]%*% t(X[k,]);
  }
prior=rep(1/25, 25); 
 
print("Bayesian D-optimal design for logistic regression");
print("model: Pr(y=1) = 1-Pr(y=0) = 1/(1+exp(-b1-b2*x))");
print("design variable: -1<=x<=2 discretized");
print("prior on b: uniform on {b1, b2 = -2, -1, 0, 1, 2}"); 

## use cocktail algorithm (alg=1)
w=bayesD(A, prior, maxiter=10000, small=1e-4, alpha=0, alg=1)

print("output:");
print("optimal support points x(i)");
print(X[w>0, 2]);
print("optimal weights w(i)");
print(w[w>0]);

Mis_redirected¢DtypeEvalueõIhttp_code¢DtypeEvalueÈQdownload_complete¢DtypeEvalueõ
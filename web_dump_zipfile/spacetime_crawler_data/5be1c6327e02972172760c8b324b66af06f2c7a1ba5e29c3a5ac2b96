¦Ifinal_url¢DtypeEvaluex3https://www.ics.uci.edu/~jmoorkan/project/index.htmLhttp_headers¢DtypeEvalue‡¢Ak¢DtypeEvalueNContent-LengthAv¢DtypeEvalueD4559¢Ak¢DtypeEvalueMAccept-RangesAv¢DtypeEvalueEbytes¢Ak¢DtypeEvalueFServerAv¢DtypeEvalueX4Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips SVN/1.7.14¢Ak¢DtypeEvalueMLast-ModifiedAv¢DtypeEvalueXMon, 13 Jul 2009 20:04:06 GMT¢Ak¢DtypeEvalueDETagAv¢DtypeEvalueT"11cf-46e9bd302b980"¢Ak¢DtypeEvalueDDateAv¢DtypeEvalueXThu, 07 Feb 2019 00:38:10 GMT¢Ak¢DtypeEvalueLContent-TypeAv¢DtypeEvalueXtext/html; charset=UTF-8Kraw_content¢DtypeEvalueYÑ<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">

<meta name="KEYWORDS" content="Spiking Neuron Convolution GPU" />

<TITLE>PROJECTS </TITLE> 
</HEAD>

<A NAME="ijcnn2009">
<BODY TEXT="#000077" BGCOLOR="#FFFFFF" <P>
<B><FONT COLOR="#FF0000"><FONT SIZE=+2>
Efficient Simulation of Large-Scale Spiking Neural
Networks Using CUDA Graphics Processors
</FONT></FONT></B></A>

<P><I><FONT COLOR="#000000">
IJCNN
</FONT></I><FONT COLOR="#000000">(2009)
</FONT>

<P><FONT COLOR="#000000">
Jayram Moorkanikara Nageswaran, Nikil Dutt, Jeffrey L Krichmar, Alex Nicolau, Alex V
</FONT>

<P>

<P><FONT COLOR="#000000"><B><FONT SIZE=+1>Abstract.</FONT></B> 
Abstractï¿½Neural network simulators that take into account
the spiking behavior of neurons are useful for studying brain
mechanisms and for engineering applications. Spiking Neural
Network (SNN) simulators have been traditionally simulated
on large-scale clusters, super-computers, or on dedicated
hardware architectures. Alternatively, Graphics Processing
Units (GPUs) can provide a low-cost, programmable, and highperformance
computing platform for simulation of SNNs. In
this paper we demonstrate an efficient, Izhikevich neuron
based large-scale SNN simulator that runs on a single GPU.
The GPU-SNN model (running on an NVIDIA GTX-280 with
1GB of memory), is up to 26 times faster than a CPU version
for the simulation of 100K neurons with 50 Million synaptic
connections, firing at an average rate of 7Hz. For simulation of
100K neurons with 10 Million synaptic connections, the GPUSNN
model is only 1.5 times slower than real-time. Further, we
present a collection of new techniques related to parallelism
extraction, mapping of irregular communication, and compact
network representation for effective simulation of SNNs on
GPUs. The fidelity of the simulation results were validated
against CPU simulations using firing rate, synaptic weight
distribution, and inter-spike interval analysis. We intend to
make our simulator available to the modeling community so
that researchers will have easy access to large-scale SNN
simulations.
</P>

<P><FONT COLOR="#000000"> <B> Software Developers: </B> Jayram Moorkanikara Nageswaran, Micah Richert, Michael Wei </FONT>

<P><FONT COLOR="#000000">
Full text in <A HREF="../pub/gpusnn-ijcnn.pdf">PDF file</A>, &nbsp; <a href='gpusnn2.tar.gz'>Source Code (Version 0.2) </a>
</FONT>

<A NAME="cudajaer">
<BODY TEXT="#000077" BGCOLOR="#FFFFFF" <P>
<B><FONT COLOR="#FF0000"><FONT SIZE=+2>
Computing Spike Based Convolutions on GPUs
</FONT></FONT></B></A>

<P><I><FONT COLOR="#000000">
ISCAS
</FONT></I><FONT COLOR="#000000">(2008)
</FONT>

<P><FONT COLOR="#000000">
Jayram Moorkanikara Nageswaran, Yingxue Wang, Tobi Delbruck, Nikil Dutt
</FONT>

<P>

<P><FONT COLOR="#000000"><B><FONT SIZE=+1>Abstract.</FONT></B> 
In spiking neural networks, asynchronous spike
events are processed in parallel by neurons. Emulations of such
networks are traditionally computed by CPUs or realized using
dedicated neuromorphic hardware. In many neuromorphic
systems, the Address-Event-Representation (AER) is used for
spike communication. In this paper we present the acceleration
of AER based spike processing using a Graphics Processing Unit
(GPU). In our experiment we interface a 128x128 pixel AER
vision sensor to a spiking neural network implemented on a
GPU for real-time convolution-based nonlinear feature
extraction with convolution kernel sizes ranging from 48x48 to
112x112 pixels. We show parallelism-performance trade-offs on
GPUs for single spike per thread, multiple spikes per thread,
and multiple objects parallelism techniques. Our
implementation can achieve a kernel speedup of up to 35x on a
single NVIDIA GTX280 board when compared to a CPU-only
implementation.
</P>

<P><FONT COLOR="#000000">
Full text in
<A HREF="../pub/cudajaerISCAS2009.pdf">PDF file</A>, &nbsp; <a href=''>Source Code (to be provided)</a>
</FONT>


<CENTER>
[<a href="../index.htm">home</a>]
[<a href="../index.htm#research">research</a>]
[<a href="../index.htm#pub">publications</a>]
[<a href="../index.htm#cv">cv</a>]
</CENTER>


<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-9757875-1");
pageTracker._trackPageview();
} catch(err) {}</script>

</BODY>
</HTML>
Mis_redirected¢DtypeEvalueõIhttp_code¢DtypeEvalueÈQdownload_complete¢DtypeEvalueõ
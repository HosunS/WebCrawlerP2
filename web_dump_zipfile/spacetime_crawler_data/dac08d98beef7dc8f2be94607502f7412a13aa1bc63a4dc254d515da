¦Ifinal_url¢DtypeEvaluex/https://www.ics.uci.edu/~theory/269/140110.htmlLhttp_headers¢DtypeEvalue‡¢Ak¢DtypeEvalueNContent-LengthAv¢DtypeEvalueD1297¢Ak¢DtypeEvalueMAccept-RangesAv¢DtypeEvalueEbytes¢Ak¢DtypeEvalueFServerAv¢DtypeEvalueX4Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips SVN/1.7.14¢Ak¢DtypeEvalueMLast-ModifiedAv¢DtypeEvalueXThu, 06 Apr 2017 21:08:51 GMT¢Ak¢DtypeEvalueDETagAv¢DtypeEvalueS"511-54c85ea745471"¢Ak¢DtypeEvalueDDateAv¢DtypeEvalueXThu, 31 Jan 2019 01:34:13 GMT¢Ak¢DtypeEvalueLContent-TypeAv¢DtypeEvalueXtext/html; charset=UTF-8Kraw_content¢DtypeEvalueY<!DOCTYPE html PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html>
<head>
<title>Theory Seminar, January 10, 2014</title>
</head>
<body>
<a href="/~theory/"><img src="http://www.ics.uci.edu/~theory/logo/CATOC2.jpg"></a>
<h2><a href="/~theory/269/">CS 269S, Winter 2014: Theory Seminar</a><br>
Bren Hall, Room 1423, 1pm

<hr>
January 10, 2014:</h2>
<h1>
Fast and Accurate k-means for Large Datasets
</h1>
<h2>
Michael Shindler
</h2>
<p>
Clustering is a popular problem with many applications. We consider
the $k$-means problem in the situation where the data is too large to
be stored in main memory and must be accessed sequentially, such as
from a disk, and where we must use as little memory as possible. Our
algorithm is based on recent theoretical results, with significant
improvements to make it practical. Our approach greatly simplifies a
recently developed algorithm, both in design and in analysis, and
eliminates large constant factors in both the approximation guarantee
and the memory requirements. We then incorporate approximate nearest
neighbor search to compute $k$-means in $o(nk)$ (whereas computing
the cost, given a solution, takes $\Theta(nk)$ time). We show that
our algorithm compares favorably to existing algorithms - both
theoretically and experimentally.
</p>

</body>
</html>

Mis_redirected¢DtypeEvalueõIhttp_code¢DtypeEvalueÈQdownload_complete¢DtypeEvalueõ
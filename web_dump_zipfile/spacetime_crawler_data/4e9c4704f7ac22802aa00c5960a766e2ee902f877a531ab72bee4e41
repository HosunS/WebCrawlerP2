¦Ifinal_url¡DtypeLhttp_headers¢DtypeEvalue‡¢Ak¢DtypeEvalueNContent-LengthAv¢DtypeEvalueD2276¢Ak¢DtypeEvalueMAccept-RangesAv¢DtypeEvalueEbytes¢Ak¢DtypeEvalueFServerAv¢DtypeEvalueX4Apache/2.4.6 (CentOS) OpenSSL/1.0.2k-fips SVN/1.7.14¢Ak¢DtypeEvalueMLast-ModifiedAv¢DtypeEvalueXSun, 29 Apr 2018 17:38:29 GMT¢Ak¢DtypeEvalueDETagAv¢DtypeEvalueS"8e4-56b0034939485"¢Ak¢DtypeEvalueDDateAv¢DtypeEvalueXFri, 01 Feb 2019 22:11:34 GMT¢Ak¢DtypeEvalueLContent-TypeAv¢DtypeEvalueXtext/html; charset=UTF-8Kraw_content¢DtypeEvalueYä<HTML>
<span style="color:#000000; font:16px Arial, Helvetica, sans-serif;">

<center>
<H3>CompSci 267P Homework #1</H3>
</center>
<OL>
<LI> [Sayood p.38#1]
    Suppose X is a random variable that takes on values
    from an M-letter alphabet.
    Show that 0 <u>&lt;</u> H(X) <u>&lt;</u> lg M.
<BR> &nbsp;

<LI> [Sayood p.38#3]
    Given an alphabet {<I>a,b,c,d</I>}, find the first-order entropy
    in the following cases:
   <BR> (<I>a</I>) P(<I>a</I>)=P(<I>b</I>)=P(<I>c</I>)=P(<I>d</I>) = 1/4
   <BR> (<I>b</I>) P(<I>a</I>)= 1/2, P(<I>b</I>)= 1/4, P(<I>c</I>)=P(<I>d</I>)= 1/8
   <BR> (<I>c</I>) P(<I>a</I>)=0.505, P(<I>b</I>)=1/4, P(<I>c</I>)=1/8, P(<I>d</I>)=.12
<BR> &nbsp;

<LI> [Sayood p.39#6abcd]
Conduct an experiment to see how well a model can describe a source.
<BR>
(a) Write a program that randomly selects letters from the 26-letter
alphabet and forms four-letter words.  Form 100 such words and see
how many of these words make sense.  Do this several times and
determine the approximate expected number of sensible words.
<BR>
<BR>
(b) File
<a href="/~dan/class/267P/datasets/text/4letter.words">http://www.ics.uci.edu/~dan/class/267P/datasets/text/4letter.words</a>&nbsp; &nbsp;
contains a list of four-letter words. Using this file, and remembering
to fold upper- and lower-case letters, obtain a probability model for
the alphabet.
<BR>
Repeat part (a) generating words using the probability model.
(You may use the random number generator located in file
<a href="/~dan/class/267P/programs/random.c">http://www.ics.uci.edu/~dan/class/267P/programs/random.c</a>&nbsp; &nbsp;)&nbsp;
Compare your results with part (a).
<BR>
<BR>
(c) Repeat part (b) using a single-letter context.
<BR>
<BR>
(d) Repeat part (b) using a two-letter context.
<BR> &nbsp;

<LI> (a) Find the entropy of a source with 6 symbols
     having probabilities .5, .2, .1, .1, .05, and .05.
<BR> &nbsp;
<BR> (b) An information source has 128 equally probable symbols.
     How long is a message from the source whose entropy is 56 bits?
<BR> &nbsp;
<BR> (c) What is the entropy of a message of 32 symbols
     from a source with three symbols if
     <UL>
     <LI> each symbol is equally likely
     <LI> the symbol probabilities are .6, .3, and .1.
     </UL>
</OL>
</span>
</HTML>
Mis_redirected¢DtypeEvalueôIhttp_code¢DtypeEvalueÈQdownload_complete¢DtypeEvalueõ